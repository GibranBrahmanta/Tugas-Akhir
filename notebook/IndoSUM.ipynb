{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdea912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import used modules and configure it\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "sys.path.append('../')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37183e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import other dependencies\n",
    "\n",
    "from extractive_text_summarizer.summarizer import Summarizer\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb306f8",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb1c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_json(json_object):\n",
    "    \"\"\"Print json in a beatiful format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    json_object: json object\n",
    "        Json file that want to be printed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    res = json.dumps(json_object, indent=2)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_jsonl(path):\n",
    "    \"\"\"Open jsonl and convert it into list of string formatted json\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: string\n",
    "        jsonl filepath\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list of string formatted json\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4dd01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_json(data):\n",
    "    \"\"\"Convert string formatted json into json\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: string\n",
    "        string formatted json\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    json\n",
    "        json\n",
    "    \"\"\"\n",
    "    \n",
    "    return json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6baf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indosum_comparasion(lst_par, lst_sum):\n",
    "    \"\"\"Convert string formatted json into json\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lst_par: three dimensional list\n",
    "        each index on the first list represent a paragraph in a document\n",
    "        each index on the second list represent a sentence in a document \n",
    "    lst_sum: two dimensional list\n",
    "        each index on the second list represent a boolean value whether a sentence is included in the extractive summary or not\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    two dimensional list\n",
    "        list of sentences and list of extractive summaries\n",
    "    \"\"\"\n",
    "    \n",
    "    lst_sentence = []\n",
    "    pivot = []\n",
    "    for par in lst_par:\n",
    "        tmp = []\n",
    "        for sent in par:\n",
    "            tmp.append(sent)\n",
    "            lst_sentence.append(sent)\n",
    "        pivot.append(tmp)\n",
    "    sum_res = []\n",
    "    for i in range(len(lst_sum)):\n",
    "        for j in range(len(lst_sum[i])):\n",
    "            if lst_sum[i][j]:\n",
    "                sum_res.append(pivot[i][j])\n",
    "    return lst_sentence, sum_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175161d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indosum_data(partition, fold, index):\n",
    "    \"\"\"Open a indosum data and return some data related to it\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    partition: string\n",
    "        partition that what to be opened (train/test/dev)\n",
    "    fold: int\n",
    "        fold that want to be opened in a partition\n",
    "    index: int\n",
    "        index of the json file in the opened fold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    two dimensional list\n",
    "        list of sentences, list of extractive summaries, and gold standard\n",
    "    \"\"\"\n",
    "    \n",
    "    dir = \"../dataset/IndoSUM/indosum/{}.{}.jsonl\".format(partition, str(fold).zfill(2))\n",
    "    lst_json = open_jsonl(dir)\n",
    "    json_obj = convert_to_json(lst_json[index])\n",
    "    lst_par = json_obj[\"paragraphs\"]\n",
    "    lst_sum = json_obj[\"gold_labels\"]\n",
    "    gold_label = json_obj[\"summary\"]\n",
    "    lst_sen, lst_ext = create_indosum_comparasion(lst_par, lst_sum)\n",
    "    return lst_sen, lst_ext, gold_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_indosum_data(lst_fold, lst_partition):\n",
    "    \"\"\"Open all json file in all fold in 'lst_fold' and all partition in 'lst_partition'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lst_fold: list\n",
    "        list of fold that want to be opened\n",
    "    lst_partition: list\n",
    "        list of partition that want to be opened\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list of json\n",
    "    int\n",
    "        count of opened json file \n",
    "    \"\"\"\n",
    "    \n",
    "    counter = 0\n",
    "    res = {}\n",
    "    for index in lst_fold:\n",
    "        tmp = {}\n",
    "        for partition in lst_partition:\n",
    "            tmp_lst = []\n",
    "            dir = \"../dataset/IndoSUM/indosum/{}.{}.jsonl\".format(partition, str(index).zfill(2))\n",
    "            lst_json = open_jsonl(dir)\n",
    "            for json_file in lst_json:\n",
    "                tmp_lst.append(convert_to_json(json_file))\n",
    "            tmp[partition] = tmp_lst\n",
    "            counter += len(tmp_lst)\n",
    "        res[index] = tmp\n",
    "    return res, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67440aee",
   "metadata": {},
   "source": [
    "# Model Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49fea3e",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0eff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences(lst_word):\n",
    "    \"\"\"Convert list of word into a sentence\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lst_word: list\n",
    "        list of word\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        a sentenece\n",
    "    \"\"\"\n",
    "    \n",
    "    res = \"\"\n",
    "    for i in range(len(lst_word) - 1):\n",
    "        tmp = lst_word[i]\n",
    "        tmp_next = lst_word[i+1]\n",
    "        res += tmp\n",
    "        if len(tmp) > 1 and len(tmp_next) > 1: \n",
    "            res += \" \"\n",
    "    return res + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comparasion(doc, gold_label, sum_res, lst_topic_word):\n",
    "    \"\"\"Print document, gold_standard, model result and topic vector in a beautiful format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc: two dimensional list \n",
    "        document that used for the summarization process\n",
    "    gold_label: two dimensional list\n",
    "        summary gold standard\n",
    "    sum_res: two dimensional list\n",
    "        model result\n",
    "    lst_topic_word: two dimensional lost\n",
    "        None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Original Text\")\n",
    "    print(\" \")\n",
    "    for sent in doc:\n",
    "        print(create_sentences(sent))\n",
    "    print(\" \")\n",
    "    print(\"Gold Label\")\n",
    "    print(\" \")\n",
    "    for sent in gold_label:\n",
    "        print(create_sentences(sent))\n",
    "    print(\" \")\n",
    "    print(\"Topic Word\")\n",
    "    print(\" \")\n",
    "    for topic in lst_topic_word:\n",
    "        print(topic)\n",
    "    print(\" \")\n",
    "    print(\"Model Result\")\n",
    "    print(\" \")\n",
    "    for sent in sum_res:\n",
    "        print(create_sentences(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5ba73",
   "metadata": {},
   "source": [
    "## Run Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa32992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "\n",
    "topic_modeling = \"LDA\"\n",
    "vector_space_model = {\n",
    "    \"model_name\": \"Word2Vec\"\n",
    "}\n",
    "similarity = \"Euclidean\"\n",
    "\n",
    "model = Summarizer(topic_modeling, vector_space_model, similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d3bf50",
   "metadata": {},
   "source": [
    "For vector space model, there were 3 keys that can be specified i.e.:\n",
    "1) model_name: vector space model that want to be used <br>\n",
    "2) pretrained_file: <br>\n",
    "    - pretrained model relative filepath based on ../extractive_text_summarizer/vector_space_model.py, or <br>\n",
    "    - model name based on Huggingface <br>\n",
    "3) batch_size: batch size for deep learning model <br>\n",
    "4) device: gpu device name for deep learning model <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72052aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a data\n",
    "\n",
    "partition = \"test\"         \n",
    "fold = 1                    \n",
    "index = 1288\n",
    "\n",
    "lst_sent, lst_ext, gold_label = get_indosum_data(partition, fold, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "\n",
    "num_of_topic = len(gold_label)\n",
    "num_of_words = 5\n",
    "ranking_method = \"Combined\"\n",
    "\n",
    "res, lst_topic_word = model.summarize(lst_sent, num_of_topic, num_of_words, ranking_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59350ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model result and compare it \n",
    "\n",
    "print_comparasion(lst_sent, gold_label, res, lst_topic_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0688726",
   "metadata": {},
   "source": [
    "# Create Evaluation File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0440989",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filename(dataset, \n",
    "                    topic_modeling, \n",
    "                    vector_space_model, \n",
    "                    similarity, \n",
    "                    ranking_method):\n",
    "    \"\"\"Create filepath to save model result in json format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: string \n",
    "        used dataset\n",
    "    topic_modeling: string\n",
    "        used topic modeling method\n",
    "    vector_space_model: dict\n",
    "        used vsm data\n",
    "    similarity: string\n",
    "        used similarity metric\n",
    "    ranking_method:\n",
    "        used ranking method\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        filepath of model result in json format\n",
    "    \"\"\"\n",
    "    \n",
    "    return \"../model_result/{}-{}-{}-{}-{}.json\".format(dataset, \n",
    "                                                        topic_modeling, \n",
    "                                                        vector_space_model['model_name'], \n",
    "                                                        similarity, \n",
    "                                                        ranking_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d967e1fb",
   "metadata": {},
   "source": [
    "## Create File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "\n",
    "topic_modeling = \"LDA\"\n",
    "vector_space_model = {\n",
    "    \"model_name\": \"Word2Vec\"\n",
    "}\n",
    "similarity = \"Euclidean\"\n",
    "\n",
    "model = Summarizer(topic_modeling, vector_space_model, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcf890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open used dataset\n",
    "\n",
    "all_data, counter = get_all_indosum_data(range(1, 6), [\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a045a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model result file \n",
    "\n",
    "pbar = tqdm(total=counter)\n",
    "\n",
    "num_of_words = 5\n",
    "ranking_method = \"Combined\"\n",
    "\n",
    "last = \"\"\n",
    "res = {}\n",
    "cnt = 0\n",
    "\n",
    "for fold in all_data.keys():\n",
    "    tmp = all_data[fold]\n",
    "    for partition in tmp.keys():\n",
    "        lst_json = tmp[partition]\n",
    "        for index in range(len(lst_json)):\n",
    "            last = \"{} - {} - {}\".format(fold, partition, str(index))\n",
    "            json_obj = lst_json[index]\n",
    "            lst_par = json_obj[\"paragraphs\"]\n",
    "            lst_sum = json_obj[\"gold_labels\"]\n",
    "            gold_label = json_obj[\"summary\"]\n",
    "            lst_sent, lst_ext = create_indosum_comparasion(lst_par, lst_sum)\n",
    "            if len(gold_label) == 0:\n",
    "                continue \n",
    "            num_of_topic = len(gold_label)\n",
    "            result, lst_topic_word = model.summarize(lst_sent, num_of_topic, num_of_words, ranking_method)\n",
    "            tmp_res = {\n",
    "                'hypotesis' : result,\n",
    "                'reference_ext' : lst_ext,\n",
    "                'reference' : gold_label\n",
    "            }\n",
    "            res[cnt] = tmp_res\n",
    "            pbar.update(1)\n",
    "            cnt += 1\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461779fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model result\n",
    "\n",
    "filename = create_filename(\"IndoSUM\", topic_modeling, vector_space_model, similarity, ranking_method)\n",
    "\n",
    "with open(filename, \"w\") as outfile:\n",
    "    json.dump(res, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
